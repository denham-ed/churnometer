{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Data Cleaning Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "*   Evaluate missing data\n",
        "*   Clean data\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/TelcoCustomerChurn.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate cleaned Train and Test sets, both saved under outputs/datasets/cleaned\n",
        "\n",
        "## Conclusions\n",
        "\n",
        " \n",
        "  * Data Cleaning Pipeline\n",
        "  * Drop Variables:  `['customerID', 'TotalCharges' ]`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kspgyffxear-"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/edsmacbook/Library/CloudStorage/OneDrive-Personal/code_institute/predictive_analytics/churnometer/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/edsmacbook/Library/CloudStorage/OneDrive-Personal/code_institute/predictive_analytics/churnometer'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tdAGw4Zwssu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Collected data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2ELZj83tF1g",
        "outputId": "d51e2567-7f6c-4200-b9c2-d4982d22e6fd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customerID</th>\n",
              "      <th>gender</th>\n",
              "      <th>SeniorCitizen</th>\n",
              "      <th>Partner</th>\n",
              "      <th>Dependents</th>\n",
              "      <th>tenure</th>\n",
              "      <th>PhoneService</th>\n",
              "      <th>MultipleLines</th>\n",
              "      <th>InternetService</th>\n",
              "      <th>OnlineSecurity</th>\n",
              "      <th>...</th>\n",
              "      <th>DeviceProtection</th>\n",
              "      <th>TechSupport</th>\n",
              "      <th>StreamingTV</th>\n",
              "      <th>StreamingMovies</th>\n",
              "      <th>Contract</th>\n",
              "      <th>PaperlessBilling</th>\n",
              "      <th>PaymentMethod</th>\n",
              "      <th>MonthlyCharges</th>\n",
              "      <th>TotalCharges</th>\n",
              "      <th>Churn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7590-VHVEG</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>No phone service</td>\n",
              "      <td>DSL</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Electronic check</td>\n",
              "      <td>29.85</td>\n",
              "      <td>29.85</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5575-GNVDE</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>34</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One year</td>\n",
              "      <td>No</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>56.95</td>\n",
              "      <td>1889.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3668-QPYBK</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>2</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>DSL</td>\n",
              "      <td>Yes</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Mailed check</td>\n",
              "      <td>53.85</td>\n",
              "      <td>108.15</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows Ã— 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService   \n",
              "0  7590-VHVEG  Female              0     Yes         No       1           No  \\\n",
              "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
              "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
              "\n",
              "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection   \n",
              "0  No phone service             DSL             No  ...               No  \\\n",
              "1                No             DSL            Yes  ...              Yes   \n",
              "2                No             DSL            Yes  ...               No   \n",
              "\n",
              "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling   \n",
              "0          No          No              No  Month-to-month              Yes  \\\n",
              "1          No          No              No        One year               No   \n",
              "2          No          No              No  Month-to-month              Yes   \n",
              "\n",
              "      PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
              "0  Electronic check          29.85         29.85      0  \n",
              "1      Mailed check          56.95       1889.50      0  \n",
              "2      Mailed check          53.85        108.15      1  \n",
              "\n",
              "[3 rows x 21 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_raw_path = \"outputs/datasets/collection/TelcoCustomerChurn.csv\"\n",
        "df = pd.read_csv(df_raw_path)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iue5e5GJ_vZg"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhWelcb_17dw"
      },
      "source": [
        "In Data Cleaning you are interested to check the distribution and shape of a variable with missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['TotalCharges']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
        "vars_with_missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oyi3gi2-_q1j"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'DataError' from 'pandas.core.base' (/opt/homebrew/lib/python3.11/site-packages/pandas/core/base.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m \u001b[39mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      2\u001b[0m \u001b[39mif\u001b[39;00m vars_with_missing_data:\n\u001b[1;32m      3\u001b[0m     profile \u001b[39m=\u001b[39m ProfileReport(df\u001b[39m=\u001b[39mdf[vars_with_missing_data], minimal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas_profiling/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"Main module of pandas-profiling.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m.. include:: ../../README.md\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontroller\u001b[39;00m \u001b[39mimport\u001b[39;00m pandas_decorator\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprofile_report\u001b[39;00m \u001b[39mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas_profiling/controller/pandas_decorator.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"This file add the decorator on the DataFrame object.\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m DataFrame\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprofile_report\u001b[39;00m \u001b[39mimport\u001b[39;00m ProfileReport\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprofile_report\u001b[39m(df: DataFrame, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ProfileReport:\n\u001b[1;32m      8\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Profile a DataFrame.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m        A ProfileReport of the DataFrame.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas_profiling/profile_report.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m Config, Settings\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexpectations_report\u001b[39;00m \u001b[39mimport\u001b[39;00m ExpectationsReport\n\u001b[0;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39malerts\u001b[39;00m \u001b[39mimport\u001b[39;00m AlertType\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdescribe\u001b[39;00m \u001b[39mimport\u001b[39;00m describe \u001b[39mas\u001b[39;00m describe_df\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msample\u001b[39;00m \u001b[39mimport\u001b[39;00m Sample\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas_profiling/model/alerts.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m Settings\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorrelations\u001b[39;00m \u001b[39mimport\u001b[39;00m perform_check_correlation\n\u001b[1;32m     13\u001b[0m \u001b[39m@unique\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mAlertType\u001b[39;00m(Enum):\n\u001b[1;32m     15\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Alert types\"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas_profiling/model/correlations.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmultimethod\u001b[39;00m \u001b[39mimport\u001b[39;00m multimethod\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m DataError\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas_profiling\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m Settings\n\u001b[1;32m     13\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCorrelation\u001b[39;00m:\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataError' from 'pandas.core.base' (/opt/homebrew/lib/python3.11/site-packages/pandas/core/base.py)"
          ]
        }
      ],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "if vars_with_missing_data:\n",
        "    profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
        "    profile.to_notebook_iframe()\n",
        "else:\n",
        "    print(\"There are no variables with missing data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvwabO0JsmYW"
      },
      "source": [
        "# Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "g6Zy_MglsmYo"
      },
      "outputs": [
        {
          "ename": "ContextualVersionConflict",
          "evalue": "(pandas 2.0.1 (/opt/homebrew/lib/python3.11/site-packages), Requirement.parse('pandas<2.0.0,>=1.0.0'), {'ppscore'})",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mContextualVersionConflict\u001b[0m                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mppscore\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpps\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mheatmap_corr\u001b[39m(df, threshold, figsize\u001b[39m=\u001b[39m(\u001b[39m20\u001b[39m, \u001b[39m12\u001b[39m), font_annot\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(df\u001b[39m.\u001b[39mcolumns) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/ppscore/__init__.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     \u001b[39m# Change here if project is renamed and does not equal the package name\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     dist_name \u001b[39m=\u001b[39m \u001b[39m__name__\u001b[39m\n\u001b[0;32m----> 7\u001b[0m     __version__ \u001b[39m=\u001b[39m get_distribution(dist_name)\u001b[39m.\u001b[39mversion\n\u001b[1;32m      8\u001b[0m \u001b[39mexcept\u001b[39;00m DistributionNotFound:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39munknown\u001b[39m\u001b[39m\"\u001b[39m\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pkg_resources/__init__.py:526\u001b[0m, in \u001b[0;36mget_distribution\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    524\u001b[0m     dist \u001b[39m=\u001b[39m Requirement\u001b[39m.\u001b[39mparse(dist)\n\u001b[1;32m    525\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dist, Requirement):\n\u001b[0;32m--> 526\u001b[0m     dist \u001b[39m=\u001b[39m get_provider(dist)\n\u001b[1;32m    527\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dist, Distribution):\n\u001b[1;32m    528\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected string, Requirement, or Distribution\u001b[39m\u001b[39m\"\u001b[39m, dist)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pkg_resources/__init__.py:398\u001b[0m, in \u001b[0;36mget_provider\u001b[0;34m(moduleOrReq)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return an IResourceProvider for the named module or requirement\"\"\"\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(moduleOrReq, Requirement):\n\u001b[0;32m--> 398\u001b[0m     \u001b[39mreturn\u001b[39;00m working_set\u001b[39m.\u001b[39mfind(moduleOrReq) \u001b[39mor\u001b[39;00m require(\u001b[39mstr\u001b[39;49m(moduleOrReq))[\u001b[39m0\u001b[39m]\n\u001b[1;32m    399\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m     module \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mmodules[moduleOrReq]\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pkg_resources/__init__.py:966\u001b[0m, in \u001b[0;36mWorkingSet.require\u001b[0;34m(self, *requirements)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequire\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mrequirements):\n\u001b[1;32m    958\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Ensure that distributions matching `requirements` are activated\u001b[39;00m\n\u001b[1;32m    959\u001b[0m \n\u001b[1;32m    960\u001b[0m \u001b[39m    `requirements` must be a string or a (possibly-nested) sequence\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[39m    included, even if they were already activated in this working set.\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 966\u001b[0m     needed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresolve(parse_requirements(requirements))\n\u001b[1;32m    968\u001b[0m     \u001b[39mfor\u001b[39;00m dist \u001b[39min\u001b[39;00m needed:\n\u001b[1;32m    969\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd(dist)\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pkg_resources/__init__.py:827\u001b[0m, in \u001b[0;36mWorkingSet.resolve\u001b[0;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m req_extras\u001b[39m.\u001b[39mmarkers_pass(req, extras):\n\u001b[1;32m    825\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 827\u001b[0m dist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_dist(\n\u001b[1;32m    828\u001b[0m     req, best, replace_conflicting, env, installer, required_by, to_activate\n\u001b[1;32m    829\u001b[0m )\n\u001b[1;32m    831\u001b[0m \u001b[39m# push the new requirements onto the stack\u001b[39;00m\n\u001b[1;32m    832\u001b[0m new_requirements \u001b[39m=\u001b[39m dist\u001b[39m.\u001b[39mrequires(req\u001b[39m.\u001b[39mextras)[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
            "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pkg_resources/__init__.py:873\u001b[0m, in \u001b[0;36mWorkingSet._resolve_dist\u001b[0;34m(self, req, best, replace_conflicting, env, installer, required_by, to_activate)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[39mif\u001b[39;00m dist \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m req:\n\u001b[1;32m    871\u001b[0m     \u001b[39m# Oops, the \"best\" so far conflicts with a dependency\u001b[39;00m\n\u001b[1;32m    872\u001b[0m     dependent_req \u001b[39m=\u001b[39m required_by[req]\n\u001b[0;32m--> 873\u001b[0m     \u001b[39mraise\u001b[39;00m VersionConflict(dist, req)\u001b[39m.\u001b[39mwith_context(dependent_req)\n\u001b[1;32m    874\u001b[0m \u001b[39mreturn\u001b[39;00m dist\n",
            "\u001b[0;31mContextualVersionConflict\u001b[0m: (pandas 2.0.1 (/opt/homebrew/lib/python3.11/site-packages), Requirement.parse('pandas<2.0.0,>=1.0.0'), {'ppscore'})"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "\n",
        "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=np.bool)\n",
        "        mask[np.triu_indices_from(mask)] = True\n",
        "        mask[abs(df) < threshold] = True\n",
        "\n",
        "        fig, axes = plt.subplots(figsize=figsize)\n",
        "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                    linewidth=0.5\n",
        "                    )\n",
        "        axes.set_yticklabels(df.columns, rotation=0)\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=np.bool)\n",
        "        mask[abs(df) < threshold] = True\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                         linewidth=0.05, linecolor='grey')\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "    df_corr_spearman = df.corr(method=\"spearman\")\n",
        "    df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "    pps_matrix_raw = pps.matrix(df)\n",
        "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "    print(pps_score_stats.round(3))\n",
        "\n",
        "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
        "                      figsize=(20, 12), font_annot=8):\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "    print(\"It evaluates monotonic relationship \\n\")\n",
        "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryNo1VnXSK9K"
      },
      "source": [
        "Calculate Correlations and Power Predictive Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_Z4SXf6GbED",
        "outputId": "6978dbde-ebb0-4023-af6c-b6f896ced798"
      },
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ-0L4PiSPEK"
      },
      "source": [
        "Display at Heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ioE3yuC4Q7QK",
        "outputId": "1946ffa1-2e5d-4972-eeda-45d7fe382314"
      },
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman, \n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.4, PPS_Threshold =0.2,\n",
        "                  figsize=(12,10), font_annot=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYdZHyDhu4kG"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxoVRefhu2Bk"
      },
      "source": [
        "## Assessing Missing Data Levels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcocWZkIx6nk"
      },
      "source": [
        "* Custom function to display missing data levels in a DataFrame, it shows the absolute levels, relative levels and data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "z9CoLqBhO7ga"
      },
      "outputs": [],
      "source": [
        "def EvaluateMissingData(df):\n",
        "    missing_data_absolute = df.isnull().sum()\n",
        "    missing_data_percentage = round(missing_data_absolute/len(df)*100, 2)\n",
        "    df_missing_data = (pd.DataFrame(\n",
        "                            data={\"RowsWithMissingData\": missing_data_absolute,\n",
        "                                   \"PercentageOfDataset\": missing_data_percentage,\n",
        "                                   \"DataType\": df.dtypes}\n",
        "                                    )\n",
        "                          .sort_values(by=['PercentageOfDataset'], ascending=False)\n",
        "                          .query(\"PercentageOfDataset > 0\")\n",
        "                          )\n",
        "\n",
        "    return df_missing_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHrzaG-ZhEKt"
      },
      "source": [
        "Check missing data levels for the collected dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "zxvNnLAjxCSi",
        "outputId": "e6239998-21e1-4401-80de-e25c33bbba52"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowsWithMissingData</th>\n",
              "      <th>PercentageOfDataset</th>\n",
              "      <th>DataType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TotalCharges</th>\n",
              "      <td>11</td>\n",
              "      <td>0.16</td>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              RowsWithMissingData  PercentageOfDataset DataType\n",
              "TotalCharges                   11                 0.16  float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWAI2EAp2FNM"
      },
      "source": [
        "## Data Cleaning Spreadsheet Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp-lSdVH-_-3"
      },
      "source": [
        "* Consider your spreadsheet notes on potential approaches to handle missing data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsL8yYQEyOSt"
      },
      "source": [
        "## Dealing with Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This dataset doesn't require much data cleaning, therefore we are not loading the DataCleaningEffect() function we studied in the feature-engine lesson.\n",
        "* For your future projects, this would be a moment to load that function and use it over your data-cleaning process.\n",
        "* For this project, we are skipping this part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt8Yqjy6ghyw"
      },
      "source": [
        "### Data Cleaning Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4GaYe_DgqwT"
      },
      "source": [
        "List here the data cleaning approaches you want initially to try.\n",
        "* Drop - `['customerID', 'TotalCharges' ]`\n",
        "\n",
        "\n",
        "**The list above is your guide, your map to know at which stage you are in the data-cleaning process**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W12Z8KIPoZ-8"
      },
      "source": [
        "### Split Train and Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Knk7DcVborLI",
        "outputId": "049ef5f2-c431-4a9d-fd87-00809986c38d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TrainSet shape: (5634, 21) \n",
            "TestSet shape: (1409, 21)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df,\n",
        "                                        df['Churn'],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "zdMPKBU_yCpF",
        "outputId": "df45adaf-5e93-4644-919f-6b82e51fe8b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* There are 1 variables with missing data \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowsWithMissingData</th>\n",
              "      <th>PercentageOfDataset</th>\n",
              "      <th>DataType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TotalCharges</th>\n",
              "      <td>8</td>\n",
              "      <td>0.14</td>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              RowsWithMissingData  PercentageOfDataset DataType\n",
              "TotalCharges                    8                 0.14  float64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_missing_data = EvaluateMissingData(TrainSet)\n",
        "print(f\"* There are {df_missing_data.shape[0]} variables with missing data \\n\")\n",
        "df_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUeGUUmu4qru"
      },
      "source": [
        "### Drop Variables\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLTFTio14qr8"
      },
      "source": [
        "* Hint: you may drop Variables with more than 80% of missing data since these variables will likely not add much value. However, this is not the case in this dataset\n",
        "* Step 1: imputation approach: **Drop Variables**\n",
        "* Step 2: Select variables to apply the imputation approach\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlQBeLo44qr8",
        "outputId": "6a342431-6be3-48fa-ce83-ed00489d960c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* 2 variables to drop \n",
            "\n",
            "['customerID', 'TotalCharges']\n"
          ]
        }
      ],
      "source": [
        "variables_method = ['customerID', 'TotalCharges' ]\n",
        "\n",
        "print(f\"* {len(variables_method)} variables to drop \\n\\n\"\n",
        "    f\"{variables_method}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1kKajldGrqF"
      },
      "source": [
        "* We are dropping `CustomerID` since it is a unique identifier for each customer, it doesn't add information to the dataset as it is.\n",
        "* We are dropping `TotalCharges` as for the context of the ML projects, a prospect doesn't have `TotalCharges`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7au_UdA34qr9"
      },
      "source": [
        "* Step 3: Create a separate DataFrame applying this imputation approach to the selected variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Zh9E2cEe4qr9"
      },
      "outputs": [],
      "source": [
        "from feature_engine.selection import DropFeatures\n",
        "imputer = DropFeatures(features_to_drop=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "df_method = imputer.transform(TrainSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsjRXMlU4qr9"
      },
      "source": [
        "* Step 4: Assess the effect on the variable's distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc9pg4ww_BO-"
      },
      "source": [
        "* In this case, there is no effect on the distribution of the variable, since you are not removing rows, but columns.\n",
        "* The effect might be losing features that might have a relevant impact on your machine-learning model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBq1a_Me4qr-"
      },
      "source": [
        "* Step 5: If you are satisfied, apply the transformation to your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NGO5M1k44qr-"
      },
      "outputs": [],
      "source": [
        "from feature_engine.selection import DropFeatures\n",
        "imputer = DropFeatures(features_to_drop=variables_method)\n",
        "imputer.fit(TrainSet)\n",
        "\n",
        "TrainSet, TestSet = imputer.transform(TrainSet) , imputer.transform(TestSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LozxNCVO4qr_"
      },
      "source": [
        "* Step 6: Evaluate if you have more variables to deal with. If yes, iterate. If not, you are done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "zGmZy46L4qr_",
        "outputId": "3597364f-19a3-42af-8d56-3bbcfe8675e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowsWithMissingData</th>\n",
              "      <th>PercentageOfDataset</th>\n",
              "      <th>DataType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [RowsWithMissingData, PercentageOfDataset, DataType]\n",
              "Index: []"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "EvaluateMissingData(TrainSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD--GI5Jvp8h"
      },
      "source": [
        "# Push cleaned data to Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SNWONrYwu6d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/cleaned') # create outputs/datasets/collection folder\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE3DQfy82r7I"
      },
      "source": [
        "## Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1ayKT4F2p52"
      },
      "outputs": [],
      "source": [
        "TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTTabVk-2ulD"
      },
      "source": [
        "## Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCjorYny2qCD"
      },
      "outputs": [],
      "source": [
        "TestSet.to_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Good job! Clear cell outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgNVNpuV6NV2"
      },
      "source": [
        "Well done! You can now push the changes to your GitHub Repo, using the Git commands (git add, git commit, git push)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
